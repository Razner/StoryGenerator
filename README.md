# ğŸ“œ HistoiRik  
HistoiRik est une application qui gÃ©nÃ¨re des histoires personnalisÃ©es pour enfants Ã  partir des prÃ©fÃ©rences de lâ€™utilisateur : prÃ©nom, Ã¢ge, univers, durÃ©e, ton, etc.

Lâ€™histoire est ensuite racontÃ©e Ã  voix haute grÃ¢ce Ã  un moteur TTS (Text-To-Speech) fonctionnant en local, puis affichÃ©e et sauvegardÃ©e sur la machine de lâ€™utilisateur.

## ğŸ¯ Objectif du projet

HistoiRik est un **Proof of Concept (PoC)** qui dÃ©montre comment :
- DÃ©ployer et interagir avec un modÃ¨le dâ€™IA open-source localement  
- IntÃ©grer une synthÃ¨se vocale sans connexion Internet   
- Mesurer la consommation Ã©nergÃ©tique rÃ©elle en local  

---

## ğŸ§© FonctionnalitÃ©s

â€¢ **GÃ©nÃ©ration dâ€™histoires locales**
- Utilisation dâ€™Ollama + Mistral  
- ParamÃ¨tres : prÃ©nom, Ã¢ge, genre, ton, longueur, dÃ©cor  

â€¢ **Lecture vocale (TTS local)**
- SynthÃ¨se vocale via `pyttsx3`  
- Choix de la voix, de la vitesse et du volume  

â€¢ **Interface simple**
- Choix des paramÃ¨tres  
- Bouton â€œGÃ©nÃ©rerâ€, â€œLire Ã  voix hauteâ€, â€œSauvegarderâ€  

â€¢ **Sauvegarde locale**
- Les histoires sont enregistrÃ©es en `.txt` ou `.pdf`  
- Un fichier `favoris.json` permet de garder les meilleures histoires  

â€¢ **Mode hors-ligne complet**
- Aucune API externe ni connexion Internet requise  

---

## ğŸ§± Structure du projet

| Module | Fichier | Description |
|--------|----------|-------------|
| ğŸ§  GÃ©nÃ©ration dâ€™histoire | `generateStory.py` | Utilise Ollama + Mistral pour crÃ©er lâ€™histoire |
| ğŸ—£ï¸ Lecture vocale | `tts.py` | Lecture locale de lâ€™histoire via pyttsx3 |
| ğŸ’» Interface | `ui.py` (ou `app.py`) | Interface locale (Tkinter / Flask / Streamlit) |
| ğŸ’¾ Sauvegarde | `utils.py` | Sauvegarde en .txt/.pdf et gestion des favoris |
| âš™ï¸ Lancement | `main.py` | Point dâ€™entrÃ©e du projet |
| ğŸ“š DonnÃ©es | `stories/` | Contient les histoires gÃ©nÃ©rÃ©es |
| â­ Favoris | `favoris.json` | Stocke les histoires marquÃ©es comme favorites |

---

## ğŸ§  Technologies utilisÃ©es

| Technologie | RÃ´le | Justification |
|--------------|------|----------------|
| **Python 3.11+** | Langage principal | Simple, portable, rapide Ã  prototyper |
| **Ollama** | ExÃ©cution du modÃ¨le local | Permet de lancer Mistral localement |
| **Mistral 7B** | ModÃ¨le de gÃ©nÃ©ration de texte | LÃ©ger, open-source, efficace pour le texte |
| **pyttsx3** | Text-to-Speech local | Fonctionne sans Internet, multiplateforme |
| **Tkinter / Flask / Streamlit** | Interface utilisateur | Simple, intuitive, adaptÃ©e Ã  un PoC |
| **psutil** | Mesure Ã©nergÃ©tique | Pour comparer la consommation locale |
| **Git** | Versioning & collaboration | Travail dâ€™Ã©quipe fluide et clair |

---

## âš™ï¸ Installation & Lancement

### ğŸ§± PrÃ©requis

Avant de commencer, assurez-vous dâ€™avoir installer :

- Python 3.11
- Ollama ([https://ollama.ai](https://ollama.ai))  
- Le modÃ¨le Mistral tÃ©lÃ©chargÃ© localement  

```bash
# Installation dâ€™Ollama (macOS / Linux)
curl -fsSL https://ollama.ai/install.sh | sh

# Sur Windows, tÃ©lÃ©chargez le setup :
# https://ollama.ai/download

# TÃ©lÃ©charger le modÃ¨le Mistral
ollama pull mistral

# StoryGenerator
python -m venv .venv
source .venv/bin/activate  # Linux / macOS
.venv\Scripts\activate     # Windows
pip install -r requirements.txt
